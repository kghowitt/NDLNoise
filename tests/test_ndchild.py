import glob
import gzip
import json
import random
import re

import pytest

from NDChild import NDChild, cached_child
from main import DOMAIN, progress_bar

CachedChild = cached_child(NDChild)

def find_difference(g1, g2):
    diffs = {}
    for key in g1:
        if g1[key] != g2[key]:
            diffs[key] = g1[key], g2[key]
    return diffs


DOMAIN.init_from_flatfile()

for sent in progress_bar(DOMAIN.sentences.values(),
                         desc='precomputing triggers'):
    CachedChild.precompute_sentence(sent)

runs = glob.glob('tests/run_data/*.gz')


@pytest.mark.parametrize('path', runs)
def test_drift_from_original(path):
    """Tests to ensure the behavior of NDChild has not changed.

    The directory tests/run_data contains a set of logs generated by NDChild
    runs on random languages, using randomly generated learning rates. Each
    file represents snapshots from a single child on a single language. The
    language, and learning rates are contained in the filename.

    Each of these files is a gzipped jsonl file. Each line in the file is a
    snapshot of the learner's grammar after consuming a sentence.

    """
    lang, rate, cons = re.search(r'lang(\d+):rate(\d+.\d+):cons(\d+.\d+)', path).groups()
    rate, cons = float(rate), float(cons)

    child = NDChild(rate, cons, lang)
    cached_child = CachedChild(rate, cons, lang)

    with gzip.open(path) as fh:
        for line in fh:
            data = json.loads(line)
            s = DOMAIN.sentences[data['sentence_id']]
            expected = data['grammar']
            child.consumeSentence(s)
            cached_child.consumeSentence(s)
            assert child.grammar == expected
            assert child.grammar == cached_child.grammar


all_languages = list(DOMAIN.languages.keys())
languages = [random.choice(all_languages) for _ in range(10)]


@pytest.mark.parametrize('language', languages)
def test_ndchild_parity(language):
    """Compares the behavior of NDChild and CachedChild to ensure identical
    behavior

    """
    child = NDChild(0.9, 0.005, 2253)
    cached_child = CachedChild(0.9, 0.005, 2253)

    num_sents = int(50000)
    for i in range(num_sents):
        s = DOMAIN.get_sentence_in_language(grammar_id=language)
        child.pre = dict(child.grammar)
        cached_child.pre = dict(child.grammar)
        child.consumeSentence(s)
        cached_child.consumeSentence(s)
        assert child.grammar == cached_child.grammar
